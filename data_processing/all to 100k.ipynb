{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# made by Gibeom LEE, HI LAB\n",
    "# 1M to 100k.ipynb 와 달리, folder_path안에 있는 모든 csv파일을 전부 축소 시켜줘서, 다른 폴더에 저장해주는 코드입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.signal import find_peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원본 CSV 파일이 있는 폴더 경로\n",
    "folder_path = r\"C:\\Users\\user\\Desktop\\Drive파일\\HI Lab\\0. Projects\\0. On going\\2. Aloe inspired DEG\\0. 실험자료\\4. Data measurement\\250917_40V 이상 다 찍기_기름별제외\\물방울 부피별\"\n",
    "\n",
    "# find Peak 설정\n",
    "height = 0.1  # 피크 감지 기준 전압 크기 (노이즈 레벨 고려)s\n",
    "num_samples = 10000 # 최종 줄이고자 하는 행 수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15ul_4cm.csv → Peak count: 5170\n",
      "19ul_4cm.csv → Peak count: 5511\n",
      "29ul_4cm.csv → Peak count: 5097\n",
      "55ul_4cm.csv → Peak count: 7736\n"
     ]
    }
   ],
   "source": [
    "# 결과를 저장할 새 폴더 경로 생성\n",
    "parent_dir = os.path.dirname(folder_path)\n",
    "original_folder_name = os.path.basename(folder_path)\n",
    "new_folder_name = f\"minimized_{original_folder_name}\"\n",
    "output_folder = os.path.join(parent_dir, new_folder_name)\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# 모든 CSV 파일 경로 수집\n",
    "csv_files = glob.glob(os.path.join(folder_path, \"*.csv\"))\n",
    "\n",
    "for file_path in csv_files:\n",
    "    try:\n",
    "        # CSV 파일 읽기 (헤더 없음, 앞 2줄 스킵)\n",
    "        df = pd.read_csv(file_path, header=None, names=[\"Time\", \"Voltage\"], skiprows=2)\n",
    "\n",
    "        # 피크 검출\n",
    "        peaks_positive, _ = find_peaks(df[\"Voltage\"], height=height, distance=100)\n",
    "        peaks_negative, _ = find_peaks(-df[\"Voltage\"], height=height, distance=100)\n",
    "        peaks = np.sort(np.concatenate((peaks_positive, peaks_negative)))\n",
    "\n",
    "        # 피크 개수 확인\n",
    "        num_peaks = len(peaks)\n",
    "        print(f\"{os.path.basename(file_path)} → Peak count: {num_peaks}\")\n",
    "\n",
    "        # 샘플링 인덱스 선택\n",
    "        if num_peaks >= num_samples:\n",
    "            selected_indices = np.sort(np.random.choice(peaks, num_samples, replace=False))\n",
    "        else:\n",
    "            num_non_peak_samples = num_samples - num_peaks\n",
    "            non_peak_indices = np.setdiff1d(np.arange(len(df)), peaks)\n",
    "            selected_non_peaks = np.linspace(0, len(non_peak_indices) - 1, num_non_peak_samples, dtype=int)\n",
    "            selected_non_peaks = non_peak_indices[selected_non_peaks]\n",
    "\n",
    "            selected_indices = np.sort(np.concatenate((peaks, selected_non_peaks)))\n",
    "\n",
    "        # 축소된 데이터 생성\n",
    "        filtered_df = df.iloc[selected_indices].reset_index(drop=True)\n",
    "        # ---------------------------\n",
    "        # 시간축 재설정 (0초부터 시작, 균일 간격 / endpoint=False)\n",
    "        # ---------------------------\n",
    "        t_start = df.iloc[0, 0]\n",
    "        t_end = df.iloc[-1, 0]\n",
    "        t_diff = t_end - t_start\n",
    "\n",
    "        # 반올림된 전체 구간\n",
    "        t_diff_rounded = round(t_diff)\n",
    "\n",
    "        # 데이터 개수 (축소 후)\n",
    "        N = len(filtered_df)\n",
    "\n",
    "        # 균등 간격 생성 (마지막 점 제외)\n",
    "        new_time = np.linspace(0, t_diff_rounded, N, endpoint=False)\n",
    "\n",
    "        # 시간열 교체\n",
    "        filtered_df[\"Time\"] = new_time\n",
    "\n",
    "        # ---------------------------\n",
    "        # 저장\n",
    "        # ---------------------------\n",
    "        filename = os.path.basename(file_path)\n",
    "        save_path = os.path.join(output_folder, filename)\n",
    "        filtered_df.to_csv(save_path, index=False, header=False)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
