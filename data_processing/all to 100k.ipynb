{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# made by Gibeom LEE, HI LAB\n",
    "# 1M to 100k.ipynb 와 달리, folder_path안에 있는 모든 csv파일을 전부 축소 시켜줘서, 다른 폴더에 저장해주는 코드입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.signal import find_peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원본 CSV 파일이 있는 폴더 경로\n",
    "folder_path = r\"C:\\Users\\user\\Desktop\\Drive파일\\HI Lab\\0. Projects\\0. On going\\2. Aloe inspired DEG\\0. 실험자료\\4. Data measurement\\250904_다 찍기\\csv파일\\물방울 부피 별\"\n",
    "\n",
    "# find Peak 설정\n",
    "height = 0.05  # 피크 감지 기준 전압 크기 (노이즈 레벨 고려)s\n",
    "num_samples = 10000 # 최종 줄이고자 하는 행 수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C16_5s_000.csv → Peak count: 7900\n",
      "C16_5s_010.csv → Peak count: 5411\n",
      "C16_5s_020.csv → Peak count: 5262\n",
      "C16_5s_030.csv → Peak count: 5247\n",
      "C16_5s_040.csv → Peak count: 5037\n",
      "C16_5s_050.csv → Peak count: 5270\n",
      "C16_5s_100.csv → Peak count: 4794\n",
      "C16_5s_150.csv → Peak count: 4340\n",
      "C16_5s_200.csv → Peak count: 4579\n",
      "C16_60s_000.csv → Peak count: 4567\n",
      "C16_60s_010.csv → Peak count: 4951\n",
      "C16_60s_020.csv → Peak count: 4814\n",
      "C16_60s_030.csv → Peak count: 5108\n",
      "C16_60s_040.csv → Peak count: 5260\n",
      "C16_60s_050.csv → Peak count: 5099\n",
      "C16_60s_100.csv → Peak count: 4904\n",
      "C16_60s_150.csv → Peak count: 4906\n",
      "C16_60s_200.csv → Peak count: 5319\n",
      "C30_5s_000.csv → Peak count: 4491\n",
      "C30_5s_010.csv → Peak count: 4928\n",
      "C30_5s_020.csv → Peak count: 5900\n",
      "C30_5s_030.csv → Peak count: 5372\n",
      "C30_5s_040.csv → Peak count: 5829\n",
      "C30_5s_050.csv → Peak count: 5768\n",
      "C30_5s_100.csv → Peak count: 6145\n",
      "C30_5s_150.csv → Peak count: 5805\n",
      "C30_5s_200.csv → Peak count: 5995\n",
      "C30_60s_000.csv → Peak count: 6095\n",
      "C30_60s_010.csv → Peak count: 5764\n",
      "C30_60s_020.csv → Peak count: 6065\n",
      "C30_60s_030.csv → Peak count: 6121\n",
      "C30_60s_040.csv → Peak count: 6123\n",
      "C30_60s_050.csv → Peak count: 6111\n",
      "C30_60s_100.csv → Peak count: 5599\n",
      "C30_60s_150.csv → Peak count: 5860\n",
      "C30_60s_200.csv → Peak count: 5632\n",
      "Mix_5s_000.csv → Peak count: 4954\n",
      "Mix_5s_010.csv → Peak count: 5345\n",
      "Mix_5s_020.csv → Peak count: 5772\n",
      "Mix_5s_030.csv → Peak count: 5824\n",
      "Mix_5s_040.csv → Peak count: 5139\n",
      "Mix_5s_050.csv → Peak count: 5550\n",
      "Mix_5s_100.csv → Peak count: 5649\n",
      "Mix_5s_150.csv → Peak count: 5921\n",
      "Mix_5s_200.csv → Peak count: 6046\n",
      "Mix_60s_000.csv → Peak count: 6052\n",
      "Mix_60s_010.csv → Peak count: 5319\n",
      "Mix_60s_020.csv → Peak count: 5946\n",
      "Mix_60s_030.csv → Peak count: 6163\n",
      "Mix_60s_040.csv → Peak count: 5396\n",
      "Mix_60s_050.csv → Peak count: 5457\n",
      "Mix_60s_100.csv → Peak count: 5531\n",
      "Mix_60s_150.csv → Peak count: 5445\n",
      "OTS_5s_000.csv → Peak count: 6201\n",
      "OTS_5s_010.csv → Peak count: 6312\n",
      "OTS_5s_020.csv → Peak count: 5894\n",
      "OTS_5s_030.csv → Peak count: 5791\n",
      "OTS_5s_040.csv → Peak count: 5954\n",
      "OTS_5s_050.csv → Peak count: 5560\n",
      "OTS_5s_100.csv → Peak count: 5253\n",
      "OTS_5s_150.csv → Peak count: 4862\n",
      "OTS_5s_200.csv → Peak count: 4692\n",
      "OTS_60s_000.csv → Peak count: 4919\n",
      "OTS_60s_010.csv → Peak count: 4781\n",
      "OTS_60s_020.csv → Peak count: 5041\n",
      "OTS_60s_030.csv → Peak count: 4963\n",
      "OTS_60s_040.csv → Peak count: 4804\n",
      "OTS_60s_050.csv → Peak count: 5080\n",
      "OTS_60s_100.csv → Peak count: 4958\n",
      "OTS_60s_150.csv → Peak count: 4959\n",
      "OTS_60s_200.csv → Peak count: 4913\n",
      "Ref_FEP_DEG.csv → Peak count: 7658\n"
     ]
    }
   ],
   "source": [
    "# 결과를 저장할 새 폴더 경로 생성\n",
    "parent_dir = os.path.dirname(folder_path)\n",
    "original_folder_name = os.path.basename(folder_path)\n",
    "new_folder_name = f\"minimized_{original_folder_name}\"\n",
    "output_folder = os.path.join(parent_dir, new_folder_name)\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# 모든 CSV 파일 경로 수집\n",
    "csv_files = glob.glob(os.path.join(folder_path, \"*.csv\"))\n",
    "\n",
    "for file_path in csv_files:\n",
    "    try:\n",
    "        # CSV 파일 읽기 (헤더 없음)\n",
    "        df = pd.read_csv(file_path, header=None, names=[\"Time\", \"Voltage\"], skiprows=2)\n",
    "\n",
    "        # 피크 검출\n",
    "        peaks_positive, _ = find_peaks(df[\"Voltage\"], height=height, distance=100)\n",
    "        peaks_negative, _ = find_peaks(-df[\"Voltage\"], height=height, distance=100)\n",
    "        peaks = np.sort(np.concatenate((peaks_positive, peaks_negative)))\n",
    "\n",
    "        # 피크 개수 확인\n",
    "        num_peaks = len(peaks)\n",
    "        print(f\"{os.path.basename(file_path)} → Peak count: {num_peaks}\")\n",
    "\n",
    "        if num_peaks >= num_samples:\n",
    "            selected_indices = np.sort(np.random.choice(peaks, num_samples, replace=False))\n",
    "        else:\n",
    "            num_non_peak_samples = num_samples - num_peaks\n",
    "            non_peak_indices = np.setdiff1d(np.arange(len(df)), peaks)\n",
    "            selected_non_peaks = np.linspace(0, len(non_peak_indices) - 1, num_non_peak_samples, dtype=int)\n",
    "            selected_non_peaks = non_peak_indices[selected_non_peaks]\n",
    "\n",
    "            selected_indices = np.sort(np.concatenate((peaks, selected_non_peaks)))\n",
    "\n",
    "        # 축소된 데이터 생성\n",
    "        filtered_df = df.iloc[selected_indices]\n",
    "\n",
    "        # 새 파일 이름 및 저장 경로\n",
    "        filename = os.path.basename(file_path)\n",
    "        save_path = os.path.join(output_folder, filename)\n",
    "        filtered_df.to_csv(save_path, index=False, header=False)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
