{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# made by Gibeom LEE, HI LAB\n",
    "# 1M to 100k.ipynb 와 달리, folder_path안에 있는 모든 csv파일을 전부 축소 시켜줘서, 다른 폴더에 저장해주는 코드입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.signal import find_peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원본 CSV 파일이 있는 폴더 경로\n",
    "folder_path = r\"C:\\Users\\user\\Desktop\\Drive파일\\HI Lab\\0. Projects\\0. On going\\2. Aloe inspired DEG\\0. 실험자료\\4. Data measurement\\250830_Squalane 평가\\csv파일\"\n",
    "\n",
    "# find Peak 설정\n",
    "height = 0.05  # 피크 감지 기준 전압 크기 (노이즈 레벨 고려)s\n",
    "num_samples = 10000 # 최종 줄이고자 하는 행 수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hexa_000.csv → Peak count: 7274\n",
      "hexa_010.csv → Peak count: 6088\n",
      "hexa_020.csv → Peak count: 6068\n",
      "hexa_030.csv → Peak count: 5716\n",
      "hexa_040.csv → Peak count: 5877\n",
      "hexa_050.csv → Peak count: 5429\n",
      "hexa_100.csv → Peak count: 5227\n",
      "hexa_150.csv → Peak count: 5426\n",
      "hexa_200.csv → Peak count: 5685\n",
      "hotsq_000.csv → Peak count: 5357\n",
      "hotsq_010.csv → Peak count: 5607\n",
      "hotsq_020.csv → Peak count: 5604\n",
      "hotsq_030.csv → Peak count: 5679\n",
      "hotsq_040.csv → Peak count: 5562\n",
      "hotsq_050.csv → Peak count: 5377\n",
      "hotsq_100.csv → Peak count: 5557\n",
      "hotsq_150.csv → Peak count: 5822\n",
      "hotsq_200.csv → Peak count: 5595\n",
      "hotsq_250.csv → Peak count: 6078\n",
      "OTS_000.csv → Peak count: 5587\n",
      "OTS_010.csv → Peak count: 5512\n",
      "OTS_020.csv → Peak count: 5760\n",
      "OTS_030.csv → Peak count: 6112\n",
      "OTS_040.csv → Peak count: 5572\n",
      "OTS_050.csv → Peak count: 5369\n",
      "OTS_100.csv → Peak count: 5310\n",
      "OTS_150.csv → Peak count: 5513\n",
      "OTS_200.csv → Peak count: 5089\n",
      "pdms_020.csv → Peak count: 5092\n",
      "pdms_030.csv → Peak count: 5245\n",
      "pdms_040.csv → Peak count: 5245\n",
      "pdms_050.csv → Peak count: 5272\n",
      "pdms_10.csv → Peak count: 5317\n",
      "pdms_100.csv → Peak count: 4912\n",
      "pdms_150.csv → Peak count: 5139\n",
      "pdms_200.csv → Peak count: 5221\n",
      "ref_hexa_000.csv → Peak count: 5840\n",
      "sq_000.csv → Peak count: 7219\n",
      "sq_010.csv → Peak count: 7181\n",
      "sq_020.csv → Peak count: 7173\n",
      "sq_040.csv → Peak count: 7083\n",
      "sq_050.csv → Peak count: 7062\n",
      "sq_100.csv → Peak count: 6965\n",
      "sq_150.csv → Peak count: 6986\n"
     ]
    }
   ],
   "source": [
    "# 결과를 저장할 새 폴더 경로 생성\n",
    "parent_dir = os.path.dirname(folder_path)\n",
    "original_folder_name = os.path.basename(folder_path)\n",
    "new_folder_name = f\"minimized_{original_folder_name}\"\n",
    "output_folder = os.path.join(parent_dir, new_folder_name)\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# 모든 CSV 파일 경로 수집\n",
    "csv_files = glob.glob(os.path.join(folder_path, \"*.csv\"))\n",
    "\n",
    "for file_path in csv_files:\n",
    "    try:\n",
    "        # CSV 파일 읽기 (헤더 없음)\n",
    "        df = pd.read_csv(file_path, header=None, names=[\"Time\", \"Voltage\"], skiprows=2)\n",
    "\n",
    "        # 피크 검출\n",
    "        peaks_positive, _ = find_peaks(df[\"Voltage\"], height=height, distance=100)\n",
    "        peaks_negative, _ = find_peaks(-df[\"Voltage\"], height=height, distance=100)\n",
    "        peaks = np.sort(np.concatenate((peaks_positive, peaks_negative)))\n",
    "\n",
    "        # 피크 개수 확인\n",
    "        num_peaks = len(peaks)\n",
    "        print(f\"{os.path.basename(file_path)} → Peak count: {num_peaks}\")\n",
    "\n",
    "        if num_peaks >= num_samples:\n",
    "            selected_indices = np.sort(np.random.choice(peaks, num_samples, replace=False))\n",
    "        else:\n",
    "            num_non_peak_samples = num_samples - num_peaks\n",
    "            non_peak_indices = np.setdiff1d(np.arange(len(df)), peaks)\n",
    "            selected_non_peaks = np.linspace(0, len(non_peak_indices) - 1, num_non_peak_samples, dtype=int)\n",
    "            selected_non_peaks = non_peak_indices[selected_non_peaks]\n",
    "\n",
    "            selected_indices = np.sort(np.concatenate((peaks, selected_non_peaks)))\n",
    "\n",
    "        # 축소된 데이터 생성\n",
    "        filtered_df = df.iloc[selected_indices]\n",
    "\n",
    "        # 새 파일 이름 및 저장 경로\n",
    "        filename = os.path.basename(file_path)\n",
    "        save_path = os.path.join(output_folder, filename)\n",
    "        filtered_df.to_csv(save_path, index=False, header=False)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
